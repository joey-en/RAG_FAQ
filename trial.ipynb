{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e97d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b439e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6db3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\Joy Anne\\AppData\\Local\\Temp\\ipykernel_22644\\225404614.py:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  loader = PyPDFLoader(\"data\\Sakina BP.pdf\")\n"
     ]
    }
   ],
   "source": [
    "# 2. Load your business proposal\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"data\\Sakina BP.pdf\") \n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea6dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split text into chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=500, separator='\\n')\n",
    "docs = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6fe80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joy Anne\\AppData\\Local\\Temp\\ipykernel_22644\\1061242017.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # Lightweight\n",
      "c:\\Users\\Joy Anne\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 4. Generate embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # Lightweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae09349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Store in Chroma DB\n",
    "from langchain.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3d88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Setup retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8068ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# 7. Setup LLM for generation\n",
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"deepset/roberta-base-squad2\",\n",
    "    tokenizer=\"deepset/roberta-base-squad2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf6962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joy Anne\\AppData\\Local\\Temp\\ipykernel_22644\\3500329325.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "# 8. Retrieve \n",
    "query = \"What is Sakina?\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in retrieved_docs[:2]])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cea7357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "5) Impact on Mental Health Research & Innovation:  With a well -organized database, \n",
      "Sakina will drive mental health research and discoveries, contributing to evidence -based \n",
      "practices and the development of new, innovative mental health solutions. The more data \n",
      "we gather, the better we can understand and im prove mental health care. Sakina will \n",
      "provide insights into trends, treatment efficacy, and patient outcomes, enabling continuous \n",
      "improvement in services. \n",
      " \n",
      "Business Model: \n",
      "Sakina operates under a sustainable and scalable revenue model that ensures accessibility for \n",
      "clinics and hospitals of all sizes: \n",
      "B2B Partnerships:  Subscription-based services tailored for hospitals and clinics, with \n",
      "tiered pricing to accommodate different institution needs. \n",
      " \n",
      "Open Access Resources: Free educational resources to increase mental health awareness \n",
      "and promote community engagement. \n",
      " \n",
      "Premium Features: Advanced analytics, customizable tools, and comprehensive solutions\n",
      "\n",
      "---\n",
      "\n",
      "Sakina operates under a sustainable and scalable revenue model that ensures accessibility for \n",
      "clinics and hospitals of all sizes: \n",
      "B2B Partnerships:  Subscription-based services tailored for hospitals and clinics, with \n",
      "tiered pricing to accommodate different institution needs. \n",
      " \n",
      "Open Access Resources: Free educational resources to increase mental health awareness \n",
      "and promote community engagement. \n",
      " \n",
      "Premium Features: Advanced analytics, customizable tools, and comprehensive solutions \n",
      "for institutions seeking a more robust platform to support mental health services.\n",
      "\n",
      "---\n",
      "\n",
      "As a friendly customer support, answer the question based on the above context: What is Sakina?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate \n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "As a friendly customer support, answer the question based on the above context: {query}\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "propmpt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = propmpt_template.format(context=context, query=query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e12763e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown arguments {'question': 'Human: \\nAnswer the question based only on the following context:\\n\\n5) Impact on Mental Health Research & Innovation:  With a well -organized database, \\nSakina will drive mental health research and discoveries, contributing to evidence -based \\npractices and the development of new, innovative mental health solutions. The more data \\nwe gather, the better we can understand and im prove mental health care. Sakina will \\nprovide insights into trends, treatment efficacy, and patient outcomes, enabling continuous \\nimprovement in services. \\n \\nBusiness Model: \\nSakina operates under a sustainable and scalable revenue model that ensures accessibility for \\nclinics and hospitals of all sizes: \\nB2B Partnerships:  Subscription-based services tailored for hospitals and clinics, with \\ntiered pricing to accommodate different institution needs. \\n \\nOpen Access Resources: Free educational resources to increase mental health awareness \\nand promote community engagement. \\n \\nPremium Features: Advanced analytics, customizable tools, and comprehensive solutions\\n\\n---\\n\\nSakina operates under a sustainable and scalable revenue model that ensures accessibility for \\nclinics and hospitals of all sizes: \\nB2B Partnerships:  Subscription-based services tailored for hospitals and clinics, with \\ntiered pricing to accommodate different institution needs. \\n \\nOpen Access Resources: Free educational resources to increase mental health awareness \\nand promote community engagement. \\n \\nPremium Features: Advanced analytics, customizable tools, and comprehensive solutions \\nfor institutions seeking a more robust platform to support mental health services.\\n\\n---\\n\\nAs a friendly customer support, answer the question based on the above context: What is Sakina?\\n'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 8. Use local model to answer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mqa_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Joy Anne\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:395\u001b[0m, in \u001b[0;36mQuestionAnsweringPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m    390\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    393\u001b[0m     )\n\u001b[1;32m--> 395\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(examples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Joy Anne\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:210\u001b[0m, in \u001b[0;36mQuestionAnsweringArgumentHandler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be understood\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# When user is sending a generator we need to trust it's a valid example\u001b[39;00m\n\u001b[0;32m    213\u001b[0m generator_types \u001b[38;5;241m=\u001b[39m (types\u001b[38;5;241m.\u001b[39mGeneratorType, Dataset) \u001b[38;5;28;01mif\u001b[39;00m Dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (types\u001b[38;5;241m.\u001b[39mGeneratorType,)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown arguments {'question': 'Human: \\nAnswer the question based only on the following context:\\n\\n5) Impact on Mental Health Research & Innovation:  With a well -organized database, \\nSakina will drive mental health research and discoveries, contributing to evidence -based \\npractices and the development of new, innovative mental health solutions. The more data \\nwe gather, the better we can understand and im prove mental health care. Sakina will \\nprovide insights into trends, treatment efficacy, and patient outcomes, enabling continuous \\nimprovement in services. \\n \\nBusiness Model: \\nSakina operates under a sustainable and scalable revenue model that ensures accessibility for \\nclinics and hospitals of all sizes: \\nB2B Partnerships:  Subscription-based services tailored for hospitals and clinics, with \\ntiered pricing to accommodate different institution needs. \\n \\nOpen Access Resources: Free educational resources to increase mental health awareness \\nand promote community engagement. \\n \\nPremium Features: Advanced analytics, customizable tools, and comprehensive solutions\\n\\n---\\n\\nSakina operates under a sustainable and scalable revenue model that ensures accessibility for \\nclinics and hospitals of all sizes: \\nB2B Partnerships:  Subscription-based services tailored for hospitals and clinics, with \\ntiered pricing to accommodate different institution needs. \\n \\nOpen Access Resources: Free educational resources to increase mental health awareness \\nand promote community engagement. \\n \\nPremium Features: Advanced analytics, customizable tools, and comprehensive solutions \\nfor institutions seeking a more robust platform to support mental health services.\\n\\n---\\n\\nAs a friendly customer support, answer the question based on the above context: What is Sakina?\\n'}"
     ]
    }
   ],
   "source": [
    "# 8. Use local model to answer\n",
    "result = qa_pipeline(question=prompt)\n",
    "print(\"Answer:\", result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
